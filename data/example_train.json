{'boston_housing_2': {'id': 'boston_housing_2', 'name': 'Boston Housing 2', 'type': {'_class': 'datasets', 'name': 'Dataset'}, 'pos': {'x': 495, 'y': 114}, 'connections': {'inbound': [], 'outbound': ['input_1']}, 'arguments': {'dataset': {'value': '"""\nNote : Don\'t change dataset id.\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n"""\n\n#dataset id=boston_housing_2\nclass Dataset:\n    """\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    """\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    def __init__(self) -> None:\n        """\n        Load dataset and set required variables.\n        """\n        \n        (X,Y),(x,y)  = keras.datasets.boston_housing.load_data()\n        \n        self.train_x = X \n        self.train_y = Y\n        self.test_x = x \n        self.test_y = y\n        \n        self.x_shape = (13,)\n\n# Do not change the anything.\nboston_housing_2 = Dataset()\n#end-dataset id=boston_housing_2\n                    ', 'type': 'dataset', 'render': 'dataset'}}}, 'input_1': {'id': 'input_1', 'name': 'Input 1', 'type': {'name': 'Input', '_class': 'layers'}, 'pos': {'x': 511, 'y': 244}, 'connections': {'inbound': ['boston_housing_2'], 'outbound': ['dense_1']}, 'arguments': {'shape': {'value': '( 13, )', 'type': 'str', 'render': 'text', 'options': 'shape'}, 'batch_size': {'value': 'None', 'type': 'str', 'render': 'text', 'options': 'size'}, 'name': {'value': 'None', 'type': 'str', 'render': 'text', 'options': 'name'}, 'dtype': {'value': 'None', 'type': 'str', 'render': 'text', 'options': 'dtype'}, 'sparse': {'value': 'False', 'type': 'str', 'render': 'list', 'options': 'bool'}, 'tensor': {'value': 'None', 'type': 'str', 'render': 'text', 'options': 'tensor'}, 'ragged': {'value': 'False', 'type': 'str', 'render': 'list', 'options': 'bool'}}}, 'dense_1': {'id': 'dense_1', 'name': 'Dense 1', 'type': {'name': 'Dense', '_class': 'layers'}, 'pos': {'x': 511, 'y': 355}, 'connections': {'inbound': ['input_1'], 'outbound': ['dense_2']}, 'arguments': {'units': {'value': '4', 'type': 'str', 'render': 'text', 'options': 'units'}, 'activation': {'value': 'relu', 'type': 'str', 'render': 'list', 'options': 'activation'}, 'use_bias': {'value': 'True', 'type': 'str', 'render': 'list', 'options': 'bool'}, 'kernel_regularizer': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'regularizer'}, 'bias_regularizer': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'regularizer'}, 'activity_regularizer': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'regularizer'}, 'kernel_constraint': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'constraint'}, 'bias_constraint': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'constraint'}}}, 'dense_2': {'id': 'dense_2', 'name': 'Dense 2', 'type': {'name': 'Dense', '_class': 'layers'}, 'pos': {'x': 516, 'y': 474}, 'connections': {'inbound': ['dense_1'], 'outbound': ['model_1']}, 'arguments': {'units': {'value': '1', 'type': 'str', 'render': 'text', 'options': 'units'}, 'activation': {'value': 'relu', 'type': 'str', 'render': 'list', 'options': 'activation'}, 'use_bias': {'value': 'True', 'type': 'str', 'render': 'list', 'options': 'bool'}, 'kernel_regularizer': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'regularizer'}, 'bias_regularizer': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'regularizer'}, 'activity_regularizer': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'regularizer'}, 'kernel_constraint': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'constraint'}, 'bias_constraint': {'value': 'None', 'type': 'str', 'render': 'list', 'options': 'constraint'}}}, 'model_1': {'id': 'model_1', 'name': 'Model 1', 'type': {'name': 'Model', '_class': 'models'}, 'pos': {'x': 515, 'y': 596}, 'connections': {'inbound': ['dense_2'], 'outbound': ['compile_1']}, 'arguments': {}}, 'compile_1': {'id': 'compile_1', 'name': 'Compile 1', 'type': {'name': 'Compile', '_class': 'models'}, 'pos': {'x': 514, 'y': 706}, 'connections': {'inbound': ['model_1'], 'outbound': ['train_1']}, 'arguments': {'optmizer': {'value': 'rmsprop', 'type': 'str', 'render': 'list', 'options': 'optimizer'}, 'loss': {'value': 'mean_absolute_error', 'type': 'str', 'render': 'list', 'options': 'loss'}, 'metrics': {'value': [], 'type': 'str', 'render': 'checkbox', 'options': 'metrics'}}}, 'train_1': {'id': 'train_1', 'name': 'Train 1', 'type': {'name': 'Train', '_class': 'models'}, 'pos': {'x': 517, 'y': 814}, 'connections': {'inbound': ['compile_1'], 'outbound': []}, 'arguments': {'batch_size': {'value': '8', 'type': 'int', 'render': 'text', 'options': 'batch_size'}, 'epochs': {'value': '1', 'type': 'int', 'render': 'text', 'options': 'batch_size'}}}, 'train_config': {'dataset': {'id': 'boston_housing_2', 'value': '"""\nNote : Don\'t change dataset id.\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n"""\n\n#dataset id=boston_housing_2\nclass Dataset:\n    """\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    """\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    def __init__(self) -> None:\n        """\n        Load dataset and set required variables.\n        """\n        \n        (X,Y),(x,y)  = keras.datasets.boston_housing.load_data()\n        \n        self.train_x = X \n        self.train_y = Y\n        self.test_x = x \n        self.test_y = y\n        \n        self.x_shape = (13,)\n\n# Do not change the anything.\nboston_housing_2 = Dataset()\n#end-dataset id=boston_housing_2\n                    '}, 'optimizer': None, 'loss': None, 'callbacks': [], 'model': {'id': 'model_1', 'name': 'Model 1', 'type': {'name': 'Model', '_class': 'models'}, 'pos': {'x': 515, 'y': 596}, 'connections': {'inbound': ['dense_2'], 'outbound': ['compile_1']}, 'arguments': {}}, 'compile': {'id': 'compile_1', 'name': 'Compile 1', 'type': {'name': 'Compile', '_class': 'models'}, 'pos': {'x': 514, 'y': 706}, 'connections': {'inbound': ['model_1'], 'outbound': ['train_1']}, 'arguments': {'optmizer': {'value': 'rmsprop', 'type': 'str', 'render': 'list', 'options': 'optimizer'}, 'loss': {'value': 'mean_absolute_error', 'type': 'str', 'render': 'list', 'options': 'loss'}, 'metrics': {'value': [], 'type': 'str', 'render': 'checkbox', 'options': 'metrics'}}}, 'train': {'id': 'train_1', 'name': 'Train 1', 'type': {'name': 'Train', '_class': 'models'}, 'pos': {'x': 517, 'y': 814}, 'connections': {'inbound': ['compile_1'], 'outbound': []}, 'arguments': {'batch_size': {'value': '8', 'type': 'int', 'render': 'text', 'options': 'batch_size'}, 'epochs': {'value': '1', 'type': 'int', 'render': 'text', 'options': 'batch_size'}}}}, 'input_nodes': ['input_1'], 'levels': [{'input_1'}, {'dense_1'}, {'dense_2'}, {'model_1'}, {'compile_1'}, {'train_1'}, set(), set(), set()]}