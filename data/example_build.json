{"dataset_1": {"id": "dataset_1", "name": "Dataset 1", "type": {"_class": "datasets", "name": "Dataset"}, "pos": {"x": 147, "y": 109, "offsetX": 54, "offsetY": 20}, "connections": {"inbound": [], "outbound": []}, "width": 108, "arguments": {"dataset": {"value": "\"\"\"\nNote : Don't change dataset id.\n\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n\"\"\"\n\n\n#dataset id=dataset_1\nclass Dataset:\n    \"\"\"\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    \"\"\"\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    def __init__(self) -> None:\n        \"\"\"\n        Load dataset and set required variables.\n        \"\"\"\n        train_set = glob(\".\\\\data\\\\datasets\\\\imagenet\\\\train\\\\*\\\\*\")[::8]\n        test_set = glob(\".\\\\data\\\\datasets\\\\imagenet\\\\val\\\\*\\\\*\")[::8]\n        \n        train_labels = [ i.split(\"\\\\\")[-2] for i in train_set ]\n        test_labels = [ i.split(\"\\\\\")[-2] for i in test_set ]\n\n        labels = list(set(train_labels))\n\n        self.train_y = keras.utils.to_categorical([ labels.index(i) for i in train_labels ] )\n        self.test_y = keras.utils.to_categorical([ labels.index(i) for i in test_labels ] )\n\n        self.train_x = np.zeros((len(train_set),224,224,3)).astype(np.uint8)\n        self.test_x = np.zeros((len(test_set),224,224,3)).astype(np.uint8)\n\n        def get_image(args):\n            index,path,array = args\n            im = cv2.imread(path,)[:,:,::-1]\n            im = cv2.resize(im,(224,224),interpolation=cv2.INTER_AREA)\n            array[index] = im\n            return 1\n\n\n        with ThreadPoolExecutor(max_workers=32) as executor:\n            res = executor.map(get_image,[ ( i,path,self.train_x ) for i,path in enumerate(train_set)])\n            \n        with ThreadPoolExecutor(max_workers=32) as executor:\n            res = executor.map(get_image,[ ( i,path,self.test_x ) for i,path in enumerate(test_set)])\n\n        collect()\n        \n        \n\n# Do not change the anything.\ndataset_1 = Dataset()\n#end-dataset id=dataset_1\n", "type": "dataset", "render": "dataset"}}}}