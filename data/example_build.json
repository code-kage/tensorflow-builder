{"mnist_1": {"id": "mnist_1", "name": "MNIST 1", "type": "Dataset", "pos": {"x": 451, "y": 149}, "connections": {"inbound": [], "outbound": []}, "arguments": {"dataset": {"value": "\"\"\"\nNote : Don't change dataset id.\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n\"\"\"\n\n#<dataset id=__id__>\nclass Dataset:\n    \"\"\"\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    \"\"\"\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    batch_size = 32\n    epochs = 3\n    batches = 0\n\n    def __init__(self) -> None:\n        \"\"\"\n        Load dataset and set required variables.\n        \"\"\"\n\n        (X,Y),(x,y) = keras.datasets.mnist.load_data()\n\n        self.train_x = X.reshape(-1,784) / 255\n        self.train_y = keras.utils.to_categorical(Y)\n        self.test_x = X.reshape(-1,784) / 255\n        self.test_y = keras.utils.to_categorical(Y)\n\n        self.calculate_batches()\n\n    def calculate_batches(self,):\n        self.batches = np.ceil(len(self.train_x)/self.batch_size)\n#</dataset>\n                        ", "type": "dataset", "render": "dataset"}}}}