{"train_config": {"session_id": null, "dataset": {"name": "Dataset 4", "type": {"object_class": "datasets", "name": "Dataset"}, "arguments": {"dataset": {"value": "\"\"\"\nNote : Don't change dataset id.\n\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n\"\"\"\n\n\n#dataset id=__id__\nclass Dataset:\n    \"\"\"\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    \"\"\"\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    def __init__(self) -> None:\n        \"\"\"\n        Load dataset and set required variables.\n        \"\"\"\n\n        self.train_x = None\n        self.train_y = None\n        self.test_x = None\n        self.test_y = None\n\n# Do not change the anything.\n__id__ = Dataset()\n#end-dataset id=__id__\n", "type": "dataset", "render": "dataset"}}, "id": "dataset_4", "pos": {"x": 412, "y": 527, "offsetX": 58, "offsetY": 15}, "connections": {"inbound": [], "outbound": []}, "width": 117}}, "dataset_1": {"name": "Dataset 1", "type": {"object_class": "datasets", "name": "Dataset"}, "arguments": {"dataset": {"value": "\"\"\"\nNote : Don't change dataset id.\n\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n\"\"\"\n\n\n#dataset id=__id__\nclass Dataset:\n    \"\"\"\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    \"\"\"\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    def __init__(self) -> None:\n        \"\"\"\n        Load dataset and set required variables.\n        \"\"\"\n\n        self.train_x = None\n        self.train_y = None\n        self.test_x = None\n        self.test_y = None\n\n# Do not change the anything.\n__id__ = Dataset()\n#end-dataset id=__id__\n", "type": "dataset", "render": "dataset"}}, "id": "dataset_1", "pos": {"x": 216, "y": 119, "offsetX": 58, "offsetY": 15}, "connections": {"inbound": [], "outbound": []}, "width": 117}, "dataset_2": {"name": "Dataset 2", "type": {"object_class": "datasets", "name": "Dataset"}, "arguments": {"dataset": {"value": "\"\"\"\nNote : Don't change dataset id.\n\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n\"\"\"\n\n\n#dataset id=__id__\nclass Dataset:\n    \"\"\"\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    \"\"\"\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    def __init__(self) -> None:\n        \"\"\"\n        Load dataset and set required variables.\n        \"\"\"\n\n        self.train_x = None\n        self.train_y = None\n        self.test_x = None\n        self.test_y = None\n\n# Do not change the anything.\n__id__ = Dataset()\n#end-dataset id=__id__\n", "type": "dataset", "render": "dataset"}}, "id": "dataset_2", "pos": {"x": 145, "y": 246, "offsetX": 58, "offsetY": 15}, "connections": {"inbound": [], "outbound": []}, "width": 117}, "dataset_3": {"name": "Dataset 3", "type": {"object_class": "datasets", "name": "Dataset"}, "arguments": {"dataset": {"value": "\"\"\"\nNote : Don't change dataset id.\n\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n\"\"\"\n\n\n#dataset id=__id__\nclass Dataset:\n    \"\"\"\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    \"\"\"\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    def __init__(self) -> None:\n        \"\"\"\n        Load dataset and set required variables.\n        \"\"\"\n\n        self.train_x = None\n        self.train_y = None\n        self.test_x = None\n        self.test_y = None\n\n# Do not change the anything.\n__id__ = Dataset()\n#end-dataset id=__id__\n", "type": "dataset", "render": "dataset"}}, "id": "dataset_3", "pos": {"x": 237, "y": 362, "offsetX": 58, "offsetY": 15}, "connections": {"inbound": [], "outbound": []}, "width": 117}, "dataset_4": {"name": "Dataset 4", "type": {"object_class": "datasets", "name": "Dataset"}, "arguments": {"dataset": {"value": "\"\"\"\nNote : Don't change dataset id.\n\nAll the required packages have been imported with their standard namespaces.\n\ntensorflow as tf\nkeras as keras\npandas as pd\nnumpy as np\n\nfrom sklearn.model_selection , train_test_split\n\"\"\"\n\n\n#dataset id=__id__\nclass Dataset:\n    \"\"\"\n    Dataset will be used in training \n\n    The dataset object needs to have following attributes\n\n    train_x : np.ndarray -> Training features\n    train_y : np.ndarray -> Training labels \n    test_x : np.ndarray -> Testing features\n    test_y : np.ndarray -> Testing labels\n\n    validate : bool -> Weather use validation data or not\n\n    batch_size : int -> Batch size\n    epochs : int -> Number of epochs\n    batches : int -> Number of batches ( Will be calculated automatically )\n    \"\"\"\n    train_x = None\n    test_x = None\n    train_y = None\n    test_y = None\n\n    validate = True\n\n    def __init__(self) -> None:\n        \"\"\"\n        Load dataset and set required variables.\n        \"\"\"\n\n        self.train_x = None\n        self.train_y = None\n        self.test_x = None\n        self.test_y = None\n\n# Do not change the anything.\n__id__ = Dataset()\n#end-dataset id=__id__\n", "type": "dataset", "render": "dataset"}}, "id": "dataset_4", "pos": {"x": 412, "y": 527, "offsetX": 58, "offsetY": 15}, "connections": {"inbound": [], "outbound": []}, "width": 117}}