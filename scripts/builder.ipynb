{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/example_build.json\",\"r\") as build_file:\n",
    "    build_config = load(build_file)\n",
    "    \n",
    "with open(\"../data/layer_config.json\",\"r\") as config_file:\n",
    "    layer_config = load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c354c95de1cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbuild_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Input'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Dataset'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "dataset = None\n",
    "\n",
    "for _id,config in build_config.items():\n",
    "    if config['type'] == 'Input':\n",
    "        inputs.append(_id)\n",
    "    elif config['type'] == 'Dataset':\n",
    "        dataset = _id\n",
    "    \n",
    "build_config['input_nodes'] = inputs\n",
    "\n",
    "levels = [ set() for i in range(len(build_config))]\n",
    "def setLevel(node,config,di=0):\n",
    "    levels[di].add(node)\n",
    "    if build_config[node]['connections']['outbound']:\n",
    "        for next_node in build_config[node]['connections']['outbound']: \n",
    "            setLevel(next_node,build_config,di+1)\n",
    "\n",
    "\n",
    "for inp in inputs:\n",
    "    setLevel(inp,build_config,0)\n",
    "    \n",
    "build_config['levels'] = levels\n",
    "    \n",
    "levels = [list(level) for level in levels if len(level)]\n",
    "levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inbound(inbound:list)->str:\n",
    "    return ( \"([\" + \", \".join(inbound) + \"])\" if len(inbound) > 1 else \"(\" + inbound[0] + \")\" ) if len(inbound) else \"\"\n",
    "\n",
    "def set_argument(argument,config):\n",
    "    value = config['value']\n",
    "    value = ( None if value == 'None' else f\"'{value}'\" ) if config['type'] == 'text' else value\n",
    "    return f\"    {argument}={value},\"\n",
    "    \n",
    "def build_arguments(arguments:dict)->str:\n",
    "    arguments = '\\n'.join([ set_argument(arg,cnf) for arg,cnf in arguments.items() ])\n",
    "    return arguments\n",
    "\n",
    "def build_input(layer,build_config,*args,**kwargs)->str:\n",
    "    arguments =  build_arguments(layer['arguments'])\n",
    "    return f\"\"\"#<{layer['id']}>\n",
    "{layer['id']} = layers.Input(\n",
    "{arguments}\n",
    ")\n",
    "#</{layer['id']}>\n",
    "\"\"\"\n",
    "\n",
    "def build_dense(layer,build_config,*args,**kwargs)->str:\n",
    "    arguments =  build_arguments(layer['arguments'])\n",
    "    inbound = build_inbound(layer['connections']['inbound'])\n",
    "    \n",
    "    return f\"\"\"#<{layer['id']}>\n",
    "{layer['id']} = layers.{layer['type']}(\n",
    "{arguments}\n",
    "){inbound}\n",
    "#</{layer['id']}>\n",
    "\"\"\"\n",
    "\n",
    "def build_conv2d(layer,build_config,*args,**kwargs)->str:\n",
    "    arguments =  build_arguments(layer['arguments'])\n",
    "    inbound = build_inbound(layer['connections']['inbound'])\n",
    "    \n",
    "    return f\"\"\"#<{layer['id']}>\n",
    "{layer['id']} = layers.{layer['type']}(\n",
    "{arguments}\n",
    "){inbound}\n",
    "#</{layer['id']}>\n",
    "\"\"\"\n",
    "\n",
    "def build_globalaverage2d(layer,build_config,*args,**kwargs)->str:\n",
    "    inbound = layer['connections']['inbound']\n",
    "    inbound = build_inbound(layer['connections']['inbound'])\n",
    "    \n",
    "    return f\"\"\"#<{layer['id']}>\n",
    "{layer['id']} = layers.{layer['type']}(){inbound}\n",
    "#</{layer['id']}>\n",
    "\"\"\"\n",
    "\n",
    "def build_model(layer,build_config,*args,**kwargs)->str:\n",
    "    return f\"\"\"##<{layer['id']}>\n",
    "{layer['id']} = keras.Model(\n",
    "    [ {', '.join(build_config['input_nodes'])}, ],\n",
    "    [ {', '.join(layer['connections']['inbound'])}, ]\n",
    ")\n",
    "#</{layer['id']}>\n",
    "\"\"\"\n",
    "\n",
    "def build_compile(layer,build_config,*args,**kwargs)->str:\n",
    "    model, = layer['connections']['inbound']\n",
    "    return f\"\"\"#<{layer['id']}>\n",
    "{model}.compile(\n",
    "    optimizer='{layer['arguments']['optmizer']['value']}',\n",
    "    loss='{layer['arguments']['loss']['value']}'\n",
    ")\n",
    "#</{layer['id']}>\n",
    "\"\"\"\n",
    "\n",
    "def build_train(layer,build_config,*args,**kwargs)->str:\n",
    "    return \"\"\n",
    "\n",
    "build_functions = {\n",
    "    \"Input\":build_input,\n",
    "    \"Conv2D\":build_conv2d,\n",
    "    \"GlobalAveragePooling2D\":build_globalaverage2d,\n",
    "    \"Dense\":build_dense,\n",
    "    \"Model\":build_model,\n",
    "    \"Compile\":build_compile,\n",
    "    \"Train\":build_train\n",
    "}\n",
    "\n",
    "build = \"#<layers>\\n\\n\"\n",
    "\n",
    "for level in levels:\n",
    "    for layer in level:\n",
    "        layer = build_config[layer]\n",
    "        build += build_functions[layer['type']](layer,build_config) + '\\n'\n",
    "\n",
    "build += '#</layers>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*- Code generated by Tensorflow GUI -*-\n",
      "#<import>\n",
      "import pandas as pd\n",
      "import nympy as np\n",
      "import tensorflow as tf\n",
      "\n",
      "from tensorflow import keras\n",
      "from tensorflow.keras import layers,optimizer,losses,metrics\n",
      "#</import>\n",
      "\n",
      "\"\"\"\n",
      "Note : Don't change dataset id.\n",
      "All the required packages have been imported with their standard namespaces.\n",
      "\n",
      "tensorflow as tf\n",
      "keras as keras\n",
      "pandas as pd\n",
      "numpy as np\n",
      "\n",
      "from sklearn.model_selection , train_test_split\n",
      "\"\"\"\n",
      "\n",
      "#<dataset id=__id__>\n",
      "class Dataset:\n",
      "    \"\"\"\n",
      "    Dataset will be used in training \n",
      "\n",
      "    The dataset object needs to have following attributes\n",
      "\n",
      "    train_x : np.ndarray -> Training features\n",
      "    train_y : np.ndarray -> Training labels \n",
      "    test_x : np.ndarray -> Testing features\n",
      "    test_y : np.ndarray -> Testing labels\n",
      "\n",
      "    validate : bool -> Weather use validation data or not\n",
      "\n",
      "    batch_size : int -> Batch size\n",
      "    epochs : int -> Number of epochs\n",
      "    batches : int -> Number of batches ( Will be calculated automatically )\n",
      "    \"\"\"\n",
      "    train_x = None\n",
      "    test_x = None\n",
      "    train_y = None\n",
      "    test_y = None\n",
      "\n",
      "    validate = True\n",
      "\n",
      "    batch_size = 32\n",
      "    epochs = 3\n",
      "    batches = 0\n",
      "\n",
      "    def __init__(self) -> None:\n",
      "        \"\"\"\n",
      "        Load dataset and set required variables.\n",
      "        \"\"\"\n",
      "\n",
      "        (X,Y),(x,y) = keras.datasets.mnist.load_data()\n",
      "\n",
      "        self.train_x = X.reshape(-1,784) / 255\n",
      "        self.train_y = keras.utils.to_categorical(Y)\n",
      "        self.test_x = X.reshape(-1,784) / 255\n",
      "        self.test_y = keras.utils.to_categorical(Y)\n",
      "\n",
      "        self.calculate_batches()\n",
      "\n",
      "    def calculate_batches(self,):\n",
      "        self.batches = np.ceil(len(self.train_x)/self.batch_size)\n",
      "#</dataset>\n",
      "                        \n",
      "\n",
      "dataset = Dataset()\n",
      "\n",
      "#<layers>\n",
      "\n",
      "#<input_1>\n",
      "input_1 = layers.Input(\n",
      "    shape=None,\n",
      "    batch_size=None,\n",
      "    name=None,\n",
      "    dtype=None,\n",
      "    sparse=False,\n",
      "    tensor=None,\n",
      "    ragged=False,\n",
      ")\n",
      "#</input_1>\n",
      "\n",
      "#<dense_1>\n",
      "dense_1 = layers.Dense(\n",
      "    units=32,\n",
      "    activation='relu',\n",
      "    use_bias=True,\n",
      "    kernel_initializer='glorot_uniform',\n",
      "    bias_initializer='zeros',\n",
      ")(input_1)\n",
      "#</dense_1>\n",
      "\n",
      "#<dense_2>\n",
      "dense_2 = layers.Dense(\n",
      "    units=10,\n",
      "    activation='softmax',\n",
      "    use_bias=False,\n",
      "    kernel_initializer='glorot_uniform',\n",
      "    bias_initializer='zeros',\n",
      ")(dense_1)\n",
      "#</dense_2>\n",
      "\n",
      "##<model_1>\n",
      "model_1 = keras.Model(\n",
      "    [ input_1, ],\n",
      "    [ dense_2, ]\n",
      ")\n",
      "#</model_1>\n",
      "\n",
      "#<compile_1>\n",
      "model_1.compile(\n",
      "    optimizer='adam',\n",
      "    loss='categorical_crossentropy'\n",
      ")\n",
      "#</compile_1>\n",
      "\n",
      "\n",
      "#</layers>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code = \"\"\"-*- Code generated by Tensorflow GUI -*-\n",
    "#<import>\n",
    "import pandas as pd\n",
    "import nympy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,optimizer,losses,metrics\n",
    "#</import>\n",
    "\n",
    "{dataset}\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "{build}\n",
    "\"\"\".format(\n",
    "    dataset=build_config[dataset]['arguments']['dataset']['value'],\n",
    "    build=build\n",
    ")\n",
    "\n",
    "print (code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
